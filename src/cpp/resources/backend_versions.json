{
  "comment": "This configuration file controls which llama.cpp, whisper.cpp, sd.cpp, ryzenai-server, and FLM versions are downloaded for each backend. You can modify these values to pin specific versions without rebuilding the application.",
  "llamacpp": {
    "vulkan": "b7869",
    "rocm": "b1170",
    "metal": "b7869",
    "cpu": "b7869"
  },
  "whispercpp": {
    "cpu": "v1.8.2",
    "vulkan": "v1.8.2",
    "rocm": "v1.8.2",
    "npu": "v1.8.2"
  },
  "sd-cpp": {
    "cpu": "master-506-1f30df9",
    "rocm": "master-505-e212912"
  },
  "therock": {
    "version": "7.11.0",
    "architectures": [
      "gfx908",
      "gfx90a",
      "gfx942",
      "gfx1100",
      "gfx1101",
      "gfx1102",
      "gfx1151",
      "gfx1150",
      "gfx1200",
      "gfx1201"
    ],
    "url_mapping": {
      "gfx908": "gfx90X-dcgpu",
      "gfx90a": "gfx90X-dcgpu",
      "gfx942": "gfx94X-dcgpu",
      "gfx1100": "gfx110X-all",
      "gfx1101": "gfx110X-all",
      "gfx1102": "gfx110X-all",
      "gfx1151": "gfx1151",
      "gfx1150": "gfx1150",
      "gfx1200": "gfx120X-all",
      "gfx1201": "gfx120X-all"
    }
  },
  "ryzenai-server": "v1.7.0",
  "flm": {
    "version": "v0.9.33",
    "min_npu_driver": "32.0.203.304"
  },
  "kokoro": {
    "cpu": "b14"
  },
  "clear_bin_if_lemonade_below": "9.3.2"
}
