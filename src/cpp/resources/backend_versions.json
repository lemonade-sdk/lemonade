{
  "comment": "This configuration file controls which llama.cpp, whisper.cpp, and FLM versions are downloaded for each backend. You can modify these values to pin specific versions without rebuilding the application.",
  "llamacpp": {
    "vulkan": "b7783",
    "rocm": "b1162",
    "metal": "b7783",
    "cpu": "b7783"
  },
  "whispercpp": "v1.8.2",
  "flm": {
    "version": "v0.9.27",
    "min_npu_driver": "32.0.203.304"
  }
}

