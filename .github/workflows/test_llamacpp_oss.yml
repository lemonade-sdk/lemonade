name: Test Lemonade with Llamacpp ðŸŒ©ï¸

# Note: STX Halo / ROCm / Ubuntu jobs are disabled until we can
# add the required runners

on:
  push:
    branches: ["main"]
  pull_request:
  workflow_dispatch:
  merge_group:


permissions:
  contents: read

jobs:
  test-server-llamacpp-windows:
    env:
      LEMONADE_CI_MODE: "True"
      CONDA_ENV_PATH: ./lemon-ci-env
      LEMONADE_CACHE_DIR: ./ci-cache
      GITHUB_TOKEN: ${{ secrets.GH_TOKEN }}
      PYTHONIOENCODING: utf-8

    strategy:
      matrix:
        include:
          - backend: vulkan
            runner: [stx, Windows]
          - backend: rocm
            runner: [stx-halo, Windows]

    runs-on: ${{ matrix.runner }}
    concurrency:
      group: ${{ github.workflow }}-${{ github.ref }}-${{ matrix.backend }}-${{ matrix.runner }}
      cancel-in-progress: true
    defaults:
      run:
        shell: powershell

    steps:
      - uses: actions/checkout@v3

      - name: Cleanup processes
        uses: ./.github/actions/cleanup-processes-windows

      - name: Set up Conda environment
        run: |
          # Keep conda up-to-date since they can apparently break things on the server side
          # We can probably remove this in the future
          conda update conda conda-libmamba-solver --solver classic
          if ($LASTEXITCODE -ne 0) { exit $LASTEXITCODE }

          conda create -p $env:CONDA_ENV_PATH python=3.10 -y
          if ($LASTEXITCODE -ne 0) { exit $LASTEXITCODE }

      - name: Install dependencies
        run: |
          conda run --no-capture-output -p $env:CONDA_ENV_PATH python -m pip install --upgrade pip
          if ($LASTEXITCODE -ne 0) { exit $LASTEXITCODE }
          
          conda run --no-capture-output -p $env:CONDA_ENV_PATH conda install -y pylint
          if ($LASTEXITCODE -ne 0) { exit $LASTEXITCODE }
          
          conda run --no-capture-output -p $env:CONDA_ENV_PATH pip install -e .[dev]
          if ($LASTEXITCODE -ne 0) { exit $LASTEXITCODE }
          
          conda run --no-capture-output -p $env:CONDA_ENV_PATH pip check
          if ($LASTEXITCODE -ne 0) { exit $LASTEXITCODE }

          echo "HF_HOME=$(pwd)/hf-cache" >> $GITHUB_ENV

      - name: Run lemonade Llamacpp CLI tests
        env:
          HF_HOME: "${{ env.HF_HOME }}"
        run: |
          if ("${{ matrix.backend }}" -ne "rocm") {
            conda run --no-capture-output -p $env:CONDA_ENV_PATH lemonade -i unsloth/Qwen3-0.6B-GGUF:Q4_0 llamacpp-load --backend ${{ matrix.backend }} --device cpu llm-prompt -p "Hi" --max-new-tokens 10; if ($LASTEXITCODE -ne 0) { exit 1 }
          }

          conda run --no-capture-output -p $env:CONDA_ENV_PATH lemonade -i unsloth/Qwen3-0.6B-GGUF:Q4_0 llamacpp-load --backend ${{ matrix.backend }} --device igpu llm-prompt -p "Hi" --max-new-tokens 10; if ($LASTEXITCODE -ne 0) { exit 1 }
          conda run --no-capture-output -p $env:CONDA_ENV_PATH lemonade -i unsloth/Qwen3-0.6B-GGUF:Q4_0 llamacpp-load --backend ${{ matrix.backend }} llamacpp-bench --cli -w 0 -i 2; if ($LASTEXITCODE -ne 0) { exit 1 }

      - name: Run lemonade Llamacpp API tests
        env:
          HF_HOME: "${{ env.HF_HOME }}"
        run: |
          conda run --no-capture-output -p $env:CONDA_ENV_PATH python test/server_llamacpp.py ${{ matrix.backend }}; if ($LASTEXITCODE -ne 0) { exit 1 }
          conda run --no-capture-output -p $env:CONDA_ENV_PATH python test/server_llamacpp.py ${{ matrix.backend }} --offline; if ($LASTEXITCODE -ne 0) { exit 1 }

  test-server-llamacpp-ubuntu:
    env:
      LEMONADE_CI_MODE: "True"
      CONDA_ENV_PATH: ./lemon-ci-env
      LEMONADE_CACHE_DIR: ./ci-cache
      GITHUB_TOKEN: ${{ secrets.GH_TOKEN }}

    strategy:
      matrix:
        include:
          - backend: rocm
            runner: [stx-halo, Linux]
          - backend: vulkan
            runner: [stx, Linux]

    runs-on: ${{ matrix.runner }}
    defaults:
      run:
        shell: bash

    steps:
      - uses: actions/checkout@v3

      - name: Cleanup processes
        uses: ./.github/actions/cleanup-processes-linux

      - name: Set up Conda environment
        run: |
          conda create -p $CONDA_ENV_PATH python=3.10 -y
          conda init

      - name: Install dependencies
        run: |
          source ~/miniforge3/etc/profile.d/conda.sh
          conda activate $CONDA_ENV_PATH
          python -m pip install --upgrade pip
          conda install -y pylint
          pip install -e .[dev]
          pip check

          echo "HF_HOME=$(pwd)/hf-cache" >> $GITHUB_ENV

      - name: Check Vulkan availability (diagnostic)
        run: |
          echo "=== Vulkan Diagnostic Information ==="
          
          # Check if vulkaninfo is available
          if command -v vulkaninfo &> /dev/null; then
              echo "vulkaninfo found, running diagnostic..."
              vulkaninfo --summary || echo "vulkaninfo failed with exit code $?"
          else
              echo "WARNING: vulkaninfo not found on system"
              echo "Vulkan tests may fail or hang if drivers are not properly installed"
          fi
          
          # Check for Vulkan ICD files
          echo ""
          echo "=== Checking for Vulkan ICD loader files ==="
          if [ -d "/etc/vulkan/icd.d" ]; then
              echo "ICD directory exists:"
              ls -la /etc/vulkan/icd.d/ || echo "Cannot list ICD directory"
          else
              echo "WARNING: /etc/vulkan/icd.d directory not found"
          fi
          
          # Check for GPU devices
          echo ""
          echo "=== Checking for GPU devices ==="
          if command -v lspci &> /dev/null; then
              echo "VGA/Display controllers:"
              lspci | grep -i "vga\|3d\|display" || echo "No GPU devices found"
          else
              echo "lspci not available"
          fi
          
          echo "=== End Vulkan Diagnostic ==="

      - name: Run lemonade Llamacpp CLI tests
        env:
          HF_HOME: "${{ env.HF_HOME }}"
        run: |
          source ~/miniforge3/etc/profile.d/conda.sh
          conda activate $CONDA_ENV_PATH

          if [ "${{ matrix.backend }}" != "rocm" ]; then
            lemonade -i unsloth/Qwen3-0.6B-GGUF:Q4_0 llamacpp-load --backend ${{ matrix.backend }} --device cpu llm-prompt -p "Hi" --max-new-tokens 10 || exit 1
          fi

          lemonade -i unsloth/Qwen3-0.6B-GGUF:Q4_0 llamacpp-load --backend ${{ matrix.backend }} --device igpu llm-prompt -p "Hi" --max-new-tokens 10 || exit 1
          lemonade -i unsloth/Qwen3-0.6B-GGUF:Q4_0 llamacpp-load --backend ${{ matrix.backend }} llamacpp-bench -i 2 --output-tokens 16 || exit 1

      - name: Run lemonade Llamacpp API tests
        env:
          HF_HOME: "${{ env.HF_HOME }}"
        run: |
          source ~/miniforge3/etc/profile.d/conda.sh
          conda activate $CONDA_ENV_PATH

          python test/server_llamacpp.py ${{ matrix.backend }} || exit 1
          python test/server_llamacpp.py ${{ matrix.backend }} --offline || exit 1

  test-server-llamacpp-macos:
    env:
      LEMONADE_CI_MODE: "True"
      CONDA_ENV_PATH: ./lemon-ci-env
      LEMONADE_CACHE_DIR: ./ci-cache
      GITHUB_TOKEN: ${{ secrets.GH_TOKEN }}

    strategy:
      matrix:
        python-version: ${{ github.event_name == 'push' && github.ref == 'refs/heads/main' && fromJSON('["3.10", "3.12"]') || fromJSON('["3.12"]') }}
        backend: ['metal']

    runs-on: macos-latest
    defaults:
      run:
        shell: bash

    steps:
      - uses: actions/checkout@v3

      - name: Cleanup processes
        uses: ./.github/actions/cleanup-processes-linux

      - name: Setup Miniconda
        uses: conda-incubator/setup-miniconda@v3
        with:
          miniforge-variant: Miniforge3
          miniforge-version: latest

      - name: Set up Conda environment
        run: |
          conda create -p $CONDA_ENV_PATH python=${{ matrix.python-version }} -y
          conda init

      - name: Install dependencies
        run: |
          source $CONDA/etc/profile.d/conda.sh
          conda activate $CONDA_ENV_PATH
          pip install -e .[dev]
          pip check

          echo "HF_HOME=$(pwd)/hf-cache" >> $GITHUB_ENV

      - name: Run lemonade Llamacpp API tests (Metal)
        env:
          HF_HOME: "${{ env.HF_HOME }}"
        run: |
          source $CONDA/etc/profile.d/conda.sh
          conda activate $CONDA_ENV_PATH

          python test/server_llamacpp.py metal || exit 1
          python test/server_llamacpp.py metal --offline || exit 1
